<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Embrained | Embodied Intelligence</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400&family=Outfit:wght@300;400;900&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="style.css">
    <meta name="description"
        content="Embrained, LLC: Operationalizing Synthetic Agency. Creators of Nimbar and Plexus.">
</head>

<body>

    <header class="hero">
        <div class="container">
            <h1 class="glitch text-glow" data-text="EMBRAINED">EMBRAINED</h1>
            <h2>DISAGGREGATED EMBODIED INTELLIGENCE</h2>

            <img src="assets/family_sketch.png" alt="Embrained Ecosystem: Nimbar, Plexus, and Carteso"
                class="family-image">

            <a href="#waitlist" class="btn primary-btn">JOIN WAITLIST</a>
        </div>
    </header>

    <section id="about-embrained" class="content-section">
        <div class="container">
            <h3>01 // ABOUT EMBRAINED</h3>
            <p>Embrained, LLC was founded in 2026 by Dr. Christopher Harris, a neuroscientist, creator of the SpikerBot,
                and former Principal Investigator at Backyard Brains. We are a neurorobotics company dedicated to
                democratizing access to embodied AI for enthusiasts, students, researchers, and developers.</p>

            <h4 class="section-subtitle">OUR APPROACH: DISAGGREGATED INTELLIGENCE</h4>
            <p>We reject the industry trend of cramming expensive, compromised computers onto battery-powered toys.
                Instead, we decouple the robot's "brain" from its "body." By wirelessly tethering the robot to the
                user’s powerful gaming PC or workstation, we unlock professional-grade artificial intelligence &mdash;
                such as Vision-Language-Action models &mdash; that standalone devices simply cannot handle.</p>
            <p>We extend this modular philosophy to the hardware itself, separating the sensory "head" and reflexive
                "spinal cord" from the mechanical chassis. This allows us to focus on our core strengths in AI, signal
                processing, and control, while mandating reliable, high-torque third-party platforms &mdash; like the
                Wave Rover &mdash; to ensure robust navigation performance.</p>
        </div>
    </section>

    <section id="ecosystem" class="content-section">
        <div class="container">
            <h3>02 // THE ECOSYSTEM</h3>

            <div class="grid">
                <div class="card">
                    <img src="assets/nimbar_sketch.png" alt="Nimbar Software Interface" class="product-image">
                    <h4>NIMBAR</h4>
                    <span class="tag">THE BRAIN</span>
                    <p>A desktop application that acts as the central nervous system, running heavy AI models for
                        navigation
                        and reasoning on your local computer.</p>
                </div>

                <div class="card">
                    <img src="assets/plexus_sketch.png" alt="Plexus Hardware Device" class="product-image">
                    <h4>PLEXUS</h4>
                    <span class="tag">THE HEAD</span>
                    <p>Our proprietary hardware module that handles vision, communication, and immediate safety reflexes
                        for mobile agents.</p>
                </div>

                <div class="card">
                    <img src="assets/rover_sketch.png" alt="Third Party Rover Chassis" class="product-image">
                    <h4>THE BODY</h4>
                    <span class="tag">THE CHASSIS</span>
                    <p>Because we focus on intelligence, we do not manufacture wheels. We require our users to build
                        their
                        mobile agents using specific, high-torque third-party chassis (such as the Waveshare Wave Rover)
                        to ensure robust performance.</p>
                </div>

                <div class="card">
                    <img src="assets/carteso_sketch.png" alt="Carteso Tracking Module" class="product-image">
                    <h4>CARTESO</h4>
                    <span class="tag">THE EYE</span>
                    <p>A low-cost, stationary sensory module that connects via USB. It serves as a distinct, accessible
                        entry point, allowing users to experiment with embodied AI and the Nimbar app without the need
                        for a mobile chassis.</p>
                </div>
            </div>
        </div>
    </section>

    <section id="market" class="content-section">
        <div class="container">
            <h3>03 // OUR MARKET</h3>

            <div class="about-text" style="margin-top: 2rem;">
                <p>
                    We serve the "Prosumer & Research" market &mdash; university students, engineers, and tech
                    enthusiasts
                    who have outgrown under-powered smart toys and require state-of-the-art embodied agents. By
                    integrating third-party rover chassis directly into our official build instructions, we ensure that
                    every Embrained agent is built on a foundation of quality, high-performance hardware.
                </p>
                <p>
                    We are building a future of privacy-native home robotics where we want your math, not your video.
                    By pooling our data, training together, and sharing our models, we will unlock a new era of personal
                    robots that understand your local environment and know how to act in it to support your goals.
                </p>
            </div>

        </div>
    </section>

    <section id="team" class="content-section">
        <div class="container">
            <h3>04 // THE TEAM</h3>

            <div class="team-grid">
                <!-- Christopher Harris -->
                <div class="team-content" style="margin-bottom: 4rem;">
                    <p><strong>Dr. Christopher Harris</strong><br>
                        <br>
                        <span class="tag">Founder & CEO</span>
                    </p>
                    <p>
                        A neuroscientist and neuroroboticist, Dr. Harris spent a decade exploring biological circuits,
                        intelligent behavior and conscious experience.
                    </p>
                    <p>
                        He works at the intersection of wetware, software and hardware as the creator
                        of the SpikerBot platform and former researcher at the National Institutes of Health.
                    </p>
                    <p><a href="https://www.youtube.com/watch?v=CbOJHywZ-J0" target="_blank">Watch: Christopher Harris
                            on SpikerBots</a></p>
                </div>
            </div>

            <!-- John Griffiths -->
            <div class="team-content">
                <p><strong>Dr. John Griffiths</strong><br>
                    <br>
                    <span class="tag">Computational Neuroscientist</span> <span class="tag">Special Advisor</span>
                </p>
                <p>
                    Head of the Whole Brain Modelling Group at the Krembil Centre for Neuroinformatics.
                </p>
                <p>
                    His research focuses on high-resolution, large-scale neural dynamics and multimodal neuroimaging,
                    bridging the gap between computational models and biological reality.
                </p>
                <p><a href="https://www.youtube.com/watch?v=9x6dwdle8WQ" target="_blank">Watch: Dr. Griffiths on Whole
                        Brain Modelling</a></p>
            </div>
        </div>
        </div>
        </div>
    </section>

    <section id="compliance" class="content-section">
        <div class="container">
            <h3>05 // PRIVACY & COMPLIANCE</h3>
            <div class="compliance-box">
                <p>
                    <strong>We want your math, not your video.</strong><br>
                    Our architecture is privacy-native. We utilize cryptographic visual hashing to process spatial data,
                    ensuring raw imagery is ephemeral.
                    Furthermore, all Embrained mobile agents are designed to comply with the <em>Stop Electronic
                        Stalking Act of 2025</em>, featuring hardware-level "Tally Lights" to indicate active inference.
                </p>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="footer-grid">
                <div>
                    <!-- Regulatory section removed -->
                </div>
                <div>
                    <h4>CONTACT</h4>
                    <p>Ann Arbor, Michigan<br>
                        Email: <a href="mailto:chris@embrained.ai">chris@embrained.ai</a></p>
                </div>
            </div>
            <hr>
            <p class="copyright">© 2026 Embrained, LLC. (MI ID: 900134514)</p>
        </div>
    </footer>

</body>

</html>