<!DOCTYPE html>
<html>

<head>
    <title>Embrained | Embodied Intelligence</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <!-- Consolidated CSS -->
    <link rel="stylesheet" href="css/style.css" />
    <noscript>
        <link rel="stylesheet" href="css/noscript.css" />
    </noscript>

</head>

<body class="is-preload">

    <!-- Wrapper -->
    <div id="wrapper">

        <!-- Header -->
        <header id="header">
            <div class="logo">
                <span class="icon">
                    <!-- Logo placeholder if needed -->
                </span>
            </div>
            <div class="content">
                <div class="inner">
                    <!-- Custom Intro Partial Content -->
                    <div class="content-center">


                        <div class="social-container">
                            <a href="https://www.linkedin.com/company/110520989" class="social-icon"
                                aria-label="LinkedIn">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                    <path
                                        d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z" />
                                </svg>
                            </a>
                            <a href="https://bsky.app/profile/embrained.ai" class="social-icon" aria-label="BlueSky">
                                <img src="https://cdn.simpleicons.org/bluesky/white" alt="BlueSky">
                            </a>
                            <a href="https://x.com/embrainedai" class="social-icon" aria-label="X (Twitter)">
                                <img src="https://cdn.simpleicons.org/x/white" alt="X">
                            </a>
                            <a href="https://github.com/embrained" class="social-icon" aria-label="GitHub">
                                <img src="https://cdn.simpleicons.org/github/white" alt="GitHub">
                            </a>
                        </div>

                        <div class="brand-section">
                            <span class="brand-title">EMBRAINED</span>
                            <span class="tagline"> Disaggregated Embodied Intelligence</span>

                        </div>
                    </div>
                    <!-- End Intro -->
                </div>
            </div>
            <nav>
                <ul>
                    <li><a href="#about">About</a></li>
                    <li><a href="#ecosystem">Hardware</a></li>
                    <li><a href="#software">Software</a></li>
                    <li><a href="#research">Research</a></li>
                    <li><a href="#team">Team</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
            </nav>
        </header>

        <!-- Main -->
        <div id="main">

            <!-- ABOUT / MISSION -->
            <article id="about">
                <h2 class="major">The Mission</h2>
                <span class="image main"><img src="images/family_sketch.png" alt="" /></span>

                <h3>The Challenge: Liberating Intelligence</h3>
                <p>We are witnessing a Cambrian explosion in Artificial Intelligence. In the digital realm—where data is
                    infinite and compute is centralized—AI has achieved feats previously thought impossible. Yet, these
                    vast synthetic minds remain confined to server farms and chat windows.</p>
                <p>The challenge of our time is not just building intelligence, but liberating it. We must give these
                    minds a body.</p>
                <p>However, the path to embodied AI is currently blocked by a hardware paradox. The industry trend is to
                    cram expensive, compromised computers onto battery-powered robots. This approach hits a ceiling: it
                    limits the size of the models we can run, drives the cost of robots beyond the reach of individuals,
                    and restricts access to well-funded research labs.</p>
                <p>This scarcity creates a data vacuum. Without affordable, capable bodies in the real world, we cannot
                    generate the data required to spark an intelligence explosion in the physical realm.</p>

                <h3>Our Approach: Disaggregated Intelligence</h3>
                <p>At Embrained, we solve this bottleneck through Disaggregated Intelligence.</p>
                <p>We decouple the robot’s "brain" from its "body." By wirelessly tethering the robot to your powerful
                    gaming PC or workstation via the Embrained app, we unlock professional-grade capabilities - such as
                    navigation models and vision-language-action models - that standalone devices simply cannot handle.
                </p>
                <p>The Head (Plexus): Our sensor hub is designed to retrofit the most ubiquitous, low-cost chassis in
                    the world.</p>
                <p>The Result: We serve the "Prosumer & Research" market—enthusiasts, students, and engineers—providing
                    access to state-of-the-art embodied agents without the five-figure price tag.</p>

                <h3>Privacy-Native Architecture</h3>
                <p>We are building a future of home robotics. Share your math, not your video.</p>
                <p>Our architecture utilizes local hashing to process spatial data into abstract vectors. Raw video
                    never leaves your computer. By pooling this anonymized "math," we are creating new classes of
                    foundation models.</p>
                <p>We combine autonomous exploration data with user-controlled demonstrations of advanced
                    behaviors—such as play, thigmotaxis (wall-following), patrol, and hide—to train a general
                    intelligence of physical movement.</p>
                <p>Compliance & Trust: We believe an active agent must be transparent. All Embrained hardware features a
                    hardware-level "Tally Light" (Purple LED) that physically indicates when the agent is performing
                    inference. This ensures you always know when the robot is "thinking," guaranteeing future-proof
                    compliance with emerging anti-surveillance regulations.</p>
            </article>

            <!-- ECOSYSTEM -->
            <article id="ecosystem">
                <h2 class="major">Hardware</h2>
                <!-- <span class="image main"><img src="" alt="" /></span> -->

                <div class="eco-container">

                    <!-- PLEXUS + BODY -->
                    <div class="eco-row">
                        <div class="eco-image combined-image">
                            <img src="images/plexus1.png" alt="Plexus Hardware Device">
                            <div class="plus-symbol">+</div>
                            <img src="images/diychassis1.png" alt="Standardized DIY Chassis">
                        </div>
                        <div class="eco-text">
                            <h4>PLEXUS (the Head) + CHASSIS (the Body)</h4>
                            <p>Plexus is a sensor and communications hub that integrates vision, audio, and safety
                                reflexes into a single unit. It is designed to retrofit ubiquitous robot bodies - like
                                our standardized 2WD DIY chassis - ensuring that research-grade agents remain affordable
                                and repairable.
                            </p>
                        </div>
                    </div>

                    <!-- CARTESO -->
                    <div class="eco-row">
                        <div class="eco-image">
                            <img src="images/carteso1.png" alt="Carteso Tracking Module">
                        </div>
                        <div class="eco-text">
                            <h4>CARTESO (the Eye)</h4>
                            <p class="carteso-desc">A low-cost, stationary sensory module that connects via USB. It
                                serves as a distinct, accessible entry point, allowing users to experiment with embodied
                                AI and the Embrained app without the need for a mobile chassis.</p>
                        </div>
                    </div>
                </div>
            </article>

            <!-- SOFTWARE -->
            <article id="software">
                <h2 class="major">The Embrained Software Platform</h2>
                <span class="image main software-hero"><img src="images/software1.png"
                        alt="Embrained App Interface" /></span>

                <h3>The Operating System for Embodied Intelligence</h3>
                <p>The Embrained app is a Python-based desktop application that acts as the "Central Nervous System" for
                    your embodied agents.
                    By running locally on your PC, it bypasses the compute limitations of microcontrollers, allowing you
                    to train and deploy
                    architectures ranging from VAEs and deep Q-learning networks to general navigation models and
                    massive vision-language-action models.
                </p>

                <h3>CORE CAPABILITIES</h3>
                <div class="table-wrapper">
                    <table>
                        <tbody>
                            <tr>
                                <td><strong>Multi-Somatic Support</strong></td>
                                <td>One brain, many bodies. The app natively supports Embrained's
                                    <strong>Plexus</strong>
                                    and <strong>Carteso</strong> devices, as well as BackyardBrain's
                                    <strong>SpikerBot</strong>. No
                                    hardware?
                                    Launch with the <code>--simulation</code> flag to train in PyBullet.
                                </td>
                            </tr>
                            <tr>
                                <td><strong>Hindsight Experience Replay (HER)</strong></td>
                                <td>Don't just log data; learn from it. The app automatically relabels exploratory
                                    "failures"
                                    as successful trajectories to arbitrary goals, maximizing data efficiency.</td>
                            </tr>
                            <tr>
                                <td><strong>Latent Manifold Visualization</strong></td>
                                <td>See what the robot thinks. Watch the multi-dimensional latent state of your agent
                                    navigate the manifold in real-time, visualizing subjective recall alongside live
                                    input.</td>
                            </tr>
                            <tr>
                                <td><strong>Privacy-Native</strong></td>
                                <td><strong>Share your math, not your video.</strong> Raw imagery is processed locally
                                    into abstract latent vectors before training. Your home environment stays on your
                                    machine.</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <h3>TECHNICAL STACK</h3>
                <p>Built for enthusiasts, researchers, students and developers. The software platform features a
                    high-performance <strong>FastAPI</strong>
                    backend
                    coupled with a reactive <strong>React/Node.js</strong> frontend.</p>
            </article>

            <!-- RESEARCH -->
            <article id="research">
                <h2 class="major">Research & Roadmap</h2>
                <p>We are building in public. Our goal is to gamify the "black box" of embodied AI, turning abstract
                    concepts like topological navigation into playable interactions. Here is what we are developing
                    next:</p>

                <div class="eco-container">
                    <div class="eco-row">
                        <div class="eco-text">
                            <h4>THE FLOOR IS LAVA (Cost Injection)</h4>
                            <p><strong>Concept:</strong> How do you teach a robot to avoid a hallway? You don't write
                                code;
                                you "paint" the floor red in the app's dedicated workspace. <br>
                                <strong>The Science:</strong> This visualizes <em>Pathfinding on a Weighted Graph</em>.
                                By injecting
                                infinite "cost" into specific nodes, the robot naturally reroutes—just like a biological
                                agent.
                            </p>
                        </div>
                    </div>
                    <div class="eco-row">
                        <div class="eco-text">
                            <h4>INVISIBLE FENCE (Edge Cutting)</h4>
                            <p><strong>Concept:</strong> Draw a line across a doorway, and the robot refuses to cross
                                it,
                                even if you call it.<br>
                                <strong>The Science:</strong> This demonstrates <em>Edge Deletion</em>. To the robot's
                                topological
                                brain, the connection between rooms literally ceases to exist.
                            </p>
                        </div>
                    </div>
                </div>
                <p><em>Follow our development journey on <a href="https://x.com/embrainedai">X</a> and
                        <a href="https://www.linkedin.com/company/110520989">LinkedIn</a> as we build these
                        features.</em></p>
            </article>

            <!-- TEAM -->
            <article id="team">
                <h2 class="major">Team</h2>
                <div class="box">
                    <p><strong>Est. 2026.</strong> Embrained, LLC is a neurorobotics company dedicated to democratizing
                        access to embodied AI.</p>
                </div>
                <div class="eco-container">
                    <!-- Chris Harris -->
                    <div class="eco-row">
                        <div class="eco-image">
                            <img src="images/ChrisHarris.jpg" alt="Dr. Christopher Harris" class="team-image">
                        </div>
                        <div class="eco-text">
                            <h4>Dr. Christopher Harris <br><span class="team-role">FOUNDER & CEO</span>
                            </h4>
                            <p>Dr. Christopher Harris is a neuroscientist (PhD, Sussex) and neuroroboticist. For eight
                                years, he served as a Principal Investigator at Backyard Brains, where he created the
                                SpikerBot platform to help students learn neuroscience by building spiking neural
                                circuits.</p>
                            <p>In 2026, he founded Embrained to make embodied AI accessible to everyone. His work
                                pioneers the decoupling of the robot's brain from its body, transforming commodity
                                hardware into research-grade instruments capable of collecting massive, high-quality
                                datasets. He designs architectures that allow standard PCs to drive complex agents and
                                games that reveal the inner workings of AI, making the invisible logic of neural
                                networks visible and controllable. His long-term aim is to discover which biological
                                primitives are essential for general intelligence, liveliness, and consciousness, and to
                                integrate them into the Embrained ecosystem to make them accessible to everyone.</p>
                            <p><a href="https://www.youtube.com/watch?v=CbOJHywZ-J0" target="_blank"
                                    class="team-link">Watch:
                                    Emergence in Educational Neurorobotics</a></p>
                        </div>
                    </div>

                    <!-- John Griffiths -->
                    <div class="eco-row">
                        <div class="eco-image">
                            <img src="images/JohnGriffiths.jpg" alt="Dr. John Griffiths" class="team-image">
                        </div>
                        <div class="eco-text">
                            <h4>Dr. John Griffiths <br><span class="team-role">CSO & SPECIAL
                                    ADVISOR</span></h4>
                            <p>Head of the Whole Brain Modelling Group at the Krembil Centre for Neuroinformatics. His
                                research bridges the gap between computational models and biological reality through
                                high-resolution neural dynamics.</p>
                            <p><a href="https://www.youtube.com/watch?v=9x6dwdle8WQ" target="_blank"
                                    class="team-link">Watch:
                                    Whole Brain Modelling</a></p>
                        </div>
                    </div>
                </div>
            </article>

            <!-- CONTACT -->
            <article id="contact">
                <h2 class="major">Contact</h2>
                <div class="contact-container">
                    <div class="contact-info">
                        <h3>Get in Touch</h3>
                        <p>
                            <strong>Embrained, LLC</strong><br>
                            Ann Arbor, Michigan
                        </p>
                        <p>
                            Email: <a href="mailto:chris@embrained.ai">chris@embrained.ai</a>
                        </p>
                        <p class="copyright-text">
                            © 2026 Embrained, LLC. (MI ID: 900134514)
                        </p>
                    </div>
                </div>
            </article>

        </div>

        <!-- Footer -->
        <footer id="footer">
            <p class="copyright"></p>
        </footer>

    </div>

    <!-- BG -->
    <div id="bg"></div>

    <!-- Scripts -->
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
    <script src="js/browser.min.js"></script>
    <script src="js/breakpoints.min.js"></script>
    <script src="js/util.js"></script>
    <script src="js/main.js"></script>

</body>

</html>